# Produce tile geometries based on the AoI extent and zoom level
prepare_data.py: 
  srs: EPSG:2056 
  datasets:
    shapefile: ./data/ground_truth/panels_ground_truth.gpkg  # GT labels                    
    category: class
    class_selection: ['thermal panel']      # list the desired class names 1: thermal panel, 2: PV, 3: unknown
    canton_selection: ['NE', 'VD']    # list the desired canton names 1: AG, 2: GE, 3: VD, 4: NE
  output_folder: ./output/trne/
  zoom_level: 17

# Fetch of tiles (online server) and split into 3 datasets: train, test, validation
generate_tilesets.py:
  debug_mode: 
    enable: True  # sample of tiles
    nb_tiles_max: 200
  working_directory: .
  datasets:
    aoi_tiles: output/trne/tiles.geojson
    ground_truth_labels: output/trne/labels.geojson
    image_source:
      type: XYZ                             # supported values: 1. MIL = Map Image Layer 2. WMS 3. XYZ 4. FOLDER
      year: multi-year                      # supported values: 1. multi-year (tiles of different year), 2. <year> (i.e. 2020)
      location: https://wmts.geo.admin.ch/1.0.0/ch.swisstopo.swissimage-product/default/{year}/3857/{z}/{x}/{y}.jpeg
  output_folder: output/trne/
  tile_size: 256      # per side, in pixels
  overwrite: True
  n_jobs: 10
  seed: 2
  COCO_metadata:
    year: 2024
    version: 1.0
    description: Energy facilities
    contributor: NE, GE, VD
    url: unknown
    license:
      name: unknown
      url: unknown

# Train the model with the detectron2 algorithm 
train_model.py:
  working_directory: ./output/trne/
  log_subfolder: logs
  sample_tagged_img_subfolder: sample_tagged_images
  COCO_files: # relative paths, w/ respect to the working_folder
    trn: COCO_trn.json
    val: COCO_val.json
    tst: COCO_tst.json
  detectron2_config_file: ../../config/detectron2_config.yaml # path relative to the working_folder
  model_weights:
    model_zoo_checkpoint_url: COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml

# Object detection with the optimised trained model
make_detections.py:
  working_directory: ./output/trne/
  log_subfolder: logs
  sample_tagged_img_subfolder: sample_tagged_images
  COCO_files:           # relative paths, w/ respect to the working_folder
    trn: COCO_trn.json
    val: COCO_val.json
    tst: COCO_tst.json
  detectron2_config_file: ../../config/detectron2_config.yaml # path relative to the working_folder
  model_weights:
    pth_file: ./logs/model_0002999.pth # trained model minimising the validation loss curve, monitor the training process via tensorboard (tensorboard --logdir </logs>)
  image_metadata_json: img_metadata.json
  rdp_simplification:   # rdp = Ramer-Douglas-Peucker
    enabled: True
    epsilon: 2.0        # cf. https://rdp.readthedocs.io/en/latest/
  score_lower_threshold: 0.05
  remove_det_overlap: False  # if several detections overlap (IoU > 0.5), only the one with the highest confidence score is retained

# Evaluate the detection quality for the different datasets by calculating metrics
assess_detections.py:
  working_directory: ./output/trne/
  datasets:
    ground_truth_labels: labels.geojson
    split_aoi_tiles: split_aoi_tiles.geojson # aoi = Area of Interest
    categories: category_ids.json
    detections:
      trn: trn_detections_at_0dot05_threshold.gpkg
      val: val_detections_at_0dot05_threshold.gpkg
      tst: tst_detections_at_0dot05_threshold.gpkg
  output_folder: .
  iou_threshold: 0.1
  area_threshold: 50       # area under which the polygons are discarded from assessment
  metrics_method: macro-average   # 1: macro-average ; 2: macro-weighted-average ; 3: micro-average

# Assess the final results
merge_detections.py:
  working_dir: ./output/trne/
  labels: labels.geojson
  detections:
    trn: trn_detections_at_0dot05_threshold.gpkg
    val: val_detections_at_0dot05_threshold.gpkg
    tst: tst_detections_at_0dot05_threshold.gpkg
  filter_buildings:
    enable: True
    buildings: ../../data/VD/building_footprint_swissTLM3D_VD.gpkg
  distance: 0.2 # m, distance use as a buffer to merge close polygons (likely to belong to the same object) together
  iou_threshold: 0.1
  score_threshold: 0.05
  assess: 
    enable: True
    metrics_method: macro-average   # 1: macro-average ; 2: macro-weighted-average ; 3: micro-average