# Produce tile geometries based on the AoI extent and zoom level
prepare_data.py: 
  srs: EPSG:2056 
  datasets:
    shapefile: ./output/trne/GE-TP_NE-TP/replicate3_check/labels_src.geojson # GT labels                    
    # category: class
    # class_selection: ['thermal panel', 'PV']      # list the desired class names 1: thermal panel, 2: PV, 3: unknown
    # canton_selection: ['GE', 'NE', 'VD']    # list the desired canton names 1: AG, 2: GE, 3: VD, 4: NE
  output_folder: ./output/trne/GE-TP_NE-TP/replicate3_check/
  zoom_level: 20

# Fetch of tiles (online server) and split into 3 datasets: train, test, validation
generate_tilesets.py:
  debug_mode: 
    enable: False  # sample of tiles
    nb_tiles_max: 200
  working_directory: .
  datasets:
    aoi_tiles: output/trne/GE-TP_NE-TP/replicate3_check/tiles.geojson
    ground_truth_labels: output/trne/GE-TP_NE-TP/replicate3_check/labels.geojson
    image_source:
      # type: FOLDER
      # year: multi-year                     # Optional, supported values: 1. multi-year (tiles of different year), 2. <year> (i.e. 2020)
      # location: <IMG_FOLDER_PATH>
      # srs: "EPSG:3857"
      # ############# 
      type: XYZ                             # supported values: 1. MIL = Map Image Layer 2. WMS 3. XYZ 4. FOLDER
      year: 2020                     # supported values: 1. multi-year (tiles of different year), 2. <year> (i.e. 2020)
      location: https://wmts.geo.admin.ch/1.0.0/ch.swisstopo.swissimage-product/default/{year}/3857/{z}/{x}/{y}.jpeg
  output_folder: output/trne/GE-TP_NE-TP/replicate3_check/
  tile_size: 256      # per side, in pixels
  overwrite: True
  n_jobs: 10
  seed: 2
  COCO_metadata:
    year: 2024
    version: 1.0
    description: Energy facility
    contributor: NE, GE, VD
    url: unknown
    license:
      name: unknown
      url: unknown

# Create an image mask keeping the buildings visible (optional)
mask_building.py:
  working_dir: ./data/
  image_dir: tiles/
  buildings_shp: layers/building_footprint_swissTLM3D_VD.gpkg
  transparency: True

# Train the model with the detectron2 algorithm 
train_model.py:
  working_directory: ./output/trne/
  log_subfolder: logs
  sample_tagged_img_subfolder: sample_tagged_images
  COCO_files: # relative paths, w/ respect to the working_folder
    trn: COCO_trn.json
    val: COCO_val.json
    tst: COCO_tst.json
  detectron2_config_file: ../../config/detectron2_config.yaml # path relative to the working_folder
  model_weights:
    model_zoo_checkpoint_url: COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml

# Object detection with the optimised trained model
make_detections.py:
  working_directory: ./output/trne/GE-TP_NE-TP/replicate3_check/
  log_subfolder: logs
  sample_tagged_img_subfolder: sample_tagged_images
  COCO_files:           # relative paths, w/ respect to the working_folder
    trn: COCO_trn.json
    val: COCO_val.json
    tst: COCO_tst.json
  detectron2_config_file: ../../../../config/detectron2_config.yaml # path relative to the working_folder
  model_weights:
    pth_file: ./logs/model_0013999.pth # trained model minimising the validation loss curve, monitor the training process via tensorboard (tensorboard --logdir </logs>)
  image_metadata_json: img_metadata.json
  rdp_simplification:   # rdp = Ramer-Douglas-Peucker
    enabled: False
    epsilon: 0.2        # cf. https://rdp.readthedocs.io/en/latest/
  score_lower_threshold: 0.05
  remove_det_overlap: True  # if several detections overlap (IoU > 0.5), only the one with the highest confidence score is retained

# Evaluate the detection quality for the different datasets by calculating metrics
assess_detections.py:
  working_directory: ./output/trne/GE-TP_NE-TP/replicate3_check/
  datasets:
    ground_truth_labels: labels.geojson
    split_aoi_tiles: split_aoi_tiles.geojson # aoi = Area of Interest
    categories: category_ids.json
    detections:
      trn: trn_detections_at_0dot05_threshold.gpkg
      val: val_detections_at_0dot05_threshold.gpkg
      tst: tst_detections_at_0dot05_threshold.gpkg
  output_folder: .
  iou_threshold: 0.1
  # area_threshold: 50       # area under which the polygons are discarded from assessment
  metrics_method: macro-average   # 1: macro-average ; 2: macro-weighted-average ; 3: micro-average

# Assess the final results
merge_detections.py:
  working_dir: ./output/trne/
  labels: labels.geojson
  detections:
    trn: trn_detections_at_0dot05_threshold.gpkg
    val: val_detections_at_0dot05_threshold.gpkg
    tst: tst_detections_at_0dot05_threshold.gpkg
  filter_buildings:
    enable: True
    buildings_shp: ../../data/layers/building_footprint_swissTLM3D_VD.gpkg
  distance: 0.2 # m, distance use as a buffer to merge close polygons (likely to belong to the same object) together
  iou_threshold: 0.1
  score_threshold: 0.05
  assess: 
    enable: True
    metrics_method: macro-average   # 1: macro-average ; 2: macro-weighted-average ; 3: micro-average