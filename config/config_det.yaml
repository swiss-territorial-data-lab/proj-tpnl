# Produce tile geometries based on the AoI extent and zoom level
prepare_data.py:  
  srs: "EPSG:2056"
  datasets:
    shapefile: ./data/AoI/<AOI_SHPFILE> 
  output_folder: ./output/det/
  zoom_level: 20 

# Fetch of tiles (online server) and split into 3 datasets: train, test, validation
generate_tilesets.py:
  debug_mode: 
    enable: False  # sample of tiles
    nb_tiles_max: 2000
  working_directory: .
  datasets:
    aoi_tiles: ./output/det/tiles.geojson
    image_source:
      # type: FOLDER
      # year: multi-year                     # Optional, supported values: 1. multi-year (tiles of different year), 2. <year> (i.e. 2020)
      # location: <IMG_FOLDER_PATH>
      # srs: "EPSG:3857"
      # ############# 
      type: XYZ                             # supported values: 1. MIL = Map Image Layer 2. WMS 3. XYZ 4. FOLDER
      year: 2023                  # supported values: 1. multi-year (tiles of different year), 2. <year> (i.e. 2020)
      location: https://wmts.geo.admin.ch/1.0.0/ch.swisstopo.swissimage-product/default/{year}/3857/{z}/{x}/{y}.jpeg
  output_folder: ./output/det/
  tile_size: 256      # per side, in pixels
  overwrite: True
  n_jobs: 10
  seed: 2
  COCO_metadata:
    year: 2024
    version: 1.0
    description: Energy facility
    contributor: NE, GE, VD
    url: unknown
    license:
      name: unknown
      url: unknown
    categories_file: ./data/category_ids.json

# (optional) Create an image mask keeping the buildings visible
mask_buildings.py:
  working_dir: ./data/
  image_dir: tiles/
  buildings_shp: layers/building_footprint_swissTLM3D_VD.gpkg
  transparency: True

# Object detection with the optimised trained model
make_detections.py:
  working_directory: ./output/det/
  log_subfolder: logs
  sample_tagged_img_subfolder: sample_tagged_images
  COCO_files:           # relative paths, w/ respect to the working_folder
    oth: COCO_oth.json
  detectron2_config_file: ../../config/detectron2_config.yaml # path relative to the working_folder
  model_weights:
    pth_file: ../../models/model_0014999.pth # trained model minimising the validation loss curve, monitor the training process via tensorboard (tensorboard --logdir </logs>)
  image_metadata_json: img_metadata.json
  rdp_simplification:   # rdp = Ramer-Douglas-Peucker
    enabled: False
    epsilon: 0.2       # cf. https://rdp.readthedocs.io/en/latest/
  score_lower_threshold: 0.05
  remove_det_overlap: True  # if several detections overlap (IoU > 0.5), only the one with the highest confidence score is retained

# Assess the final results
merge_detections.py:
  working_dir: ./output/trne/
  labels: labels.geojson
  detections:
    trn: trn_detections_at_0dot05_threshold.gpkg
    val: val_detections_at_0dot05_threshold.gpkg
    tst: tst_detections_at_0dot05_threshold.gpkg
  filter_buildings:
    enable: False
    buildings_shp: ../../data/VD/building_footprint_swissTLM3D_VD.gpkg
  distance: 0.2 # m, distance use as a buffer to merge close polygons (likely to belong to the same object) together
  iou_threshold: 0.1
  score_threshold: 0.05
  assess: 
    enable: False
    metrics_method: macro-average   # 1: macro-average ; 2: macro-weighted-average ; 3: micro-average

review_detections.py:
  file: ./input/<SHP_FILE>
  output: ./output/det/